<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Creative - Start Bootstrap Theme</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="../assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans:400,700" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="../../css/styles.css" rel="stylesheet" />
        <!-- Custom font -->
        <link href="../../css/font.css" rel="stylesheet" />

        <!-- MathJax -->
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top py-3" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">DH</a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto my-2 my-lg-0">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="../index.html">Blog</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="../../index.html">Portfolio</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Welcome -->
        <section class="page-section" id="article">
            <div class="container">
                <h2 class="text-left mt-0">Linear Regression</h2>
                <br>
                <p class="mb-0">
                    Recall supervised learning from <a href="ml1.html">Lecture 1</a>. The goal is to predict the label \(\hat{y} \in \mathbb{R}\) from the d-dimensional features \(x \in \mathbb{R}^d\).
                    
                    <br><br>
                    The linear regression model is a supervised learning model and is defined as follows:
                    $$\hat{y} = w_1^Tx + w_2$$
                    $$x = \begin{bmatrix}x_1\\.\\.\\x_d\end{bmatrix} \quad  w_1 = \begin{bmatrix}w_1\\.\\.\\w_d\end{bmatrix}$$
                    $$\hat{y} = (\sum_{j=1}^d w_{1, j}x_j)+w_2$$

                    \(w_1\) is the weight assigned to the inputs to determine how heavily each input affects the prediction. \(w_2\) is the bias term to offset predictions on the y-axis. The learning objective is to choose \(w_1\) and \(w_2\) based on the dataset.
                    So how do we make that choice? We use a loss function to measure how well a model is doing. This function measures the error in our predictions.

                    <br><br>
                    For linear regression, we use the squared loss function:
                    $$\frac{1}{N}\sum_{i=1}^N\frac{1}{2}(\hat{y}^i-y^i)^2$$
                    $$=\frac{1}{N}\sum_{i=1}^N\frac{1}{2}(w_1^Tx + w_2-y^i)^2$$
                    At this point in the lecture, I was wondering why we had the \(\frac{1}{2}\) term in the summation since without it, it's the average of squared error which makes sense as a loss function.
                    Later on the the lecture, we do some derivations on this function where a 2 term pops out. The \(\frac{1}{2}\) is there to benefit our future selves. It also does not affect the loss function since it's a scalar term.

                    <br><br>
                    We want to pick \(w_1\) and \(w_2\) such that the squared loss function is minimized:
                    $$\underset{w_1 \in \mathbb{R}^d, w_2 \in \mathbb{R}}{\operatorname{argmin}}\frac{1}{N}\sum_{i=1}^N\frac{1}{2}(w_1^Tx + w_2-y^i)^2$$
                    If we convert the squared loss function from a scalar error problem to a matrix problem, the math is cleaner:
                    $$ Let y:=\begin{bmatrix}y$$
                </p>
            </div>
        </section>

        <!-- Footer-->
        <footer class="bg-light py-5">
            <div class="container"><div class="small text-center text-muted">Copyright Â© 2020 - Start Bootstrap</div></div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="../../js/scripts.js"></script>
    </body>
</html>
